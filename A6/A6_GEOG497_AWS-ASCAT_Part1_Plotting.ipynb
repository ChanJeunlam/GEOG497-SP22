{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GEOG 497 - Spring 2021 - Cryosphere & Climate Systems\n",
    "## A6: Remote sensing of ice sheet surface melt\n",
    "\n",
    "## Part 1: Plotting AWS-derived melt data and co-located ASCAT backscatter\n",
    "\n",
    "Input data: \n",
    "1) Enhanced spatial resolution (4.45-km) near-daily ASCAT data. Here we're using \"all-pass\" (msfa) data for the Antarctic region. The data have been converted from the natively-provided SIR format to yearly netcdfs. \n",
    "* Source: https://www.scp.byu.edu/data/Ascat/SIR/Ascat_sir.html\n",
    "* Note if not running on Penn State's Roar system: you will need to download these data independently and convert to netcdfs. Future revisions of this assignment could instead provide time series of ASCAT data at the AWS sites. \n",
    "\n",
    "2) Estimates of in-situ surface meltwater production from Antarctic AWS sites.\n",
    "* Source: https://doi.pangaea.de/10.1594/PANGAEA.910473\n",
    "* In the code block below, data from 10 AWS sites will be downloaded from the PANGAEA data repository.\n",
    "        \n",
    "For this assignment, base code exist below that you can edit to plot ASCAT data alongside in situ melt rate data for any of the AWS sites (except AWS4, that pre-dates the ASCAT era). \n",
    "\n",
    "### Run the following two code blocks first.\n",
    "The first downloads all of the AWS data. This only needs to be done once!\n",
    "\n",
    "The next loads python packages and sets some plotting-related variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get all of the AWS data from the source\n",
    "\n",
    "import urllib.request\n",
    "\n",
    "urls = ['https://doi.pangaea.de/10.1594/PANGAEA.910467?format=textfile',\n",
    "        'https://doi.pangaea.de/10.1594/PANGAEA.910470?format=textfile',\n",
    "        'https://doi.pangaea.de/10.1594/PANGAEA.910471?format=textfile',\n",
    "        'https://doi.pangaea.de/10.1594/PANGAEA.910477?format=textfile',\n",
    "        'https://doi.pangaea.de/10.1594/PANGAEA.910479?format=textfile',\n",
    "        'https://doi.pangaea.de/10.1594/PANGAEA.910480?format=textfile',\n",
    "        'https://doi.pangaea.de/10.1594/PANGAEA.910483?format=textfile',\n",
    "        'https://doi.pangaea.de/10.1594/PANGAEA.910452?format=textfile',\n",
    "        'https://doi.pangaea.de/10.1594/PANGAEA.910465?format=textfile',\n",
    "        'https://doi.pangaea.de/10.1594/PANGAEA.910466?format=textfile']\n",
    "\n",
    "filenames = ['IMAU_aws11_high-res_meteo.tab',\n",
    "             'IMAU_aws14_high-res_meteo.tab',\n",
    "             'IMAU_aws15_high-res_meteo.tab',\n",
    "             'IMAU_aws16_high-res_meteo.tab',\n",
    "             'IMAU_aws17_high-res_meteo.tab',\n",
    "             'IMAU_aws18_high-res_meteo.tab',\n",
    "             'IMAU_aws19_high-res_meteo.tab',\n",
    "             'IMAU_aws4_high-res_meteo.tab',\n",
    "             'IMAU_aws5_high-res_meteo.tab',\n",
    "             'IMAU_aws6_high-res_meteo.tab']\n",
    "\n",
    "# loop through and download AWS data to Data folder\n",
    "for i in range(len(urls)):\n",
    "    print('Downloading: ' + filenames[i])\n",
    "    urllib.request.urlretrieve(urls[i],'Data/' + filenames[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import python packages\n",
    "\n",
    "# for file searching\n",
    "import glob \n",
    "\n",
    "# for data reading/analysis\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "\n",
    "#  for geographic projections\n",
    "from pyproj import Transformer\n",
    "\n",
    "# for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as style\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.dates import DateFormatter\n",
    "\n",
    "# seaborn adds some extra visual appeal to our plots\n",
    "import seaborn as sns\n",
    "\n",
    "# Handle date time conversions between pandas and matplotlib\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "\n",
    "# set some universal plot settings here\n",
    "plt.rcParams[\"figure.dpi\"] = 200\n",
    "plt.rcParams['axes.xmargin'] = 0.05\n",
    "sns.set_style('darkgrid')\n",
    "sns.set_context(\"notebook\", font_scale=0.75)\n",
    "%config InlineBackend.figure_format = 'retina' # make high res plots for retina 5k displays\n",
    "\n",
    "# lastly, this specifies where the AWS and ASCAT data are located\n",
    "awsFolder = './Data/'\n",
    "ascatFolder = '/gpfs/group/ljt5282/default/ASCAT_data/netcdfs/annual/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary step 1: read all the ASCAT data files\n",
    "This reads all of the continent-wide, daily temporal resolution ASCAT netcdf files using `xarray`. Afterward, we will subset these data to only the grid cell nearest to the AWS location of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read all yearly netcdfs using xarray and create new xarray DataSet variable\n",
    "ascat_ds = xr.open_mfdataset(ascatFolder + 'msfa*.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main code: Plot ASCAT and AWS melt data at one location\n",
    "Code here is all set up to work and should be used as a reference for making plots at other AWS sites.\n",
    "\n",
    "In the block directly below, you'll want to specify what AWS datafile we'll want to read.\n",
    "This then loads it using `pandas` and resamples the hourly data to daily means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pandas to read SEB melt data for the AWS site\n",
    "aws_datafile = 'IMAU_aws14_high-res_meteo.tab'\n",
    "aws_folder_plus_file = awsFolder + aws_datafile\n",
    "aws_df = pd.read_csv(aws_folder_plus_file,\n",
    "                            sep='\\t', \n",
    "                            skiprows=40,\n",
    "                            parse_dates=['Date/Time'],\n",
    "                            index_col=['Date/Time'])\n",
    "\n",
    "# Resample hourly data to daily means and set as new pandas DataFrame variable\n",
    "aws_df_daily = aws_df.resample('D').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can use Pandas here to find when the AWS record starts and ends, and we'll use this to subset our ASCAT data in time\n",
    "# str() here turns the timestamp into a string and allows us to combine it with our text below\n",
    "# Note: this is only for our own information right now, but you can see below where we subset the ASCAT data where this is useful.\n",
    "\n",
    "print('First observation at AWS: ' + str(aws_df_daily.index.min()))\n",
    "print('Last observation at AWS: ' + str(aws_df_daily.index.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the latitude and longitude of where the AWS is located. \n",
    "This info can be found in the AWS data file's header:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we're using a shell command 'head' to read the first few lines of the file\n",
    "# then we're piping it through the 'grep' command to search for text we're interested in.\n",
    "# this is also a useful point to verify that we're working with the AWS number we indend to work with\n",
    "\n",
    "!head $aws_folder_plus_file | grep LATITUDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using that info from the header, specify here where this AWS is located (latitude and longitude)\n",
    "aws_lat = \n",
    "aws_lon = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use pyproj to convert lat/lon coordinates in the projected x/y coordinates of the ASCAT data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from geographic lat/lon to EPSG:3976 (WGS 84 / NSIDC Sea Ice Polar Stereographic South)\n",
    "transformer = Transformer.from_crs(\"epsg:4326\", \"epsg:3976\")\n",
    "aws_x,aws_y = transformer.transform(aws_lat, aws_lon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset the ASCAT data to the location and timespan of the AWS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, subset the ascat data to only the point (i.e., the grid cell nearest to the AWS site) and  only when it overlaps with the AWS data\n",
    "ascat_ds_ts_aws = ascat_ds['sigma0'].sel(x=aws_x, method=\"nearest\") \\\n",
    "                                    .sel(y=aws_y, method=\"nearest\") \\\n",
    "                                    .sel(time=slice(aws_df_daily.index.min(), aws_df_daily.index.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the AWS-derived melt data and ASCAT data over that site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, plot the AWS and ASCAT data\n",
    "\n",
    "# create a figure\n",
    "fig, ax = plt.subplots(figsize=(15, 7.5))\n",
    "\n",
    "# plot ascat data on first vetical axis\n",
    "line1 = ax.plot(ascat_ds_ts_aws.time, ascat_ds_ts_aws,\n",
    "                 label='ASCAT sigma0')\n",
    "\n",
    "# make second vertical axis; plot aws data on it\n",
    "ax2 = ax.twinx()\n",
    "line2 = ax2.plot(aws_df_daily['Melt rate [mm w.e.] (surface melt, within dt)'], \n",
    "                label='AWS-derived melt rate', \n",
    "                color='indianred')\n",
    "\n",
    "# Set some display properties\n",
    "ax.set(ylabel='ASCAT backscatter at AWS site [dB]',\n",
    "       xlabel='Date',\n",
    "       title='AWS14')\n",
    "\n",
    "ax2.set(ylabel='Daily mean melt rate [mm w.e.]')\n",
    "ax2.yaxis.grid(False)\n",
    "\n",
    "ax2.set_ylim((-0.5, 0.5))\n",
    "ax.set_ylim((-30, 30))\n",
    "\n",
    "# add a legend now that we have 2 lines\n",
    "lines = line1 + line2\n",
    "labels = [l.get_label() for l in lines]\n",
    "ax.legend(lines, labels, loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geospatial-geog497",
   "language": "python",
   "name": "geospatial-geog497"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
