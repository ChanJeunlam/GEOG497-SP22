{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examining ice sheet data in python with `Pandas`\n",
    "## Part 2: Exploring AWS18 Data\n",
    "\n",
    "### Overview\n",
    "\n",
    "In this notebook, we'll:\n",
    "1. Explore reading a csv file to create a `pandas.DataFrame`\n",
    "2. Have `pandas` index the DataFrame based on a date/time field and interpret the dates\n",
    "3. Use `pandas` functions to summarize, plot, and subset data.\n",
    "4. Create new fields in our `DataFrame` by assessing whether particular criteria are met in a given row. \n",
    "\n",
    "\n",
    "Data source: https://doi.pangaea.de/10.1594/PANGAEA.910480\n",
    "\n",
    "Local file: `data/IMAU_aws18_high-res_meteo_daily.csv`\n",
    "\n",
    "These data are daily means generated from higher-resolution (2-hourly) AWS observations and SEB model results from AWS18 on Larsen Ice Shelf. They were previously used this semester in Assignment 2.\n",
    "\n",
    "#### To start, import some python packages and specify some options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for data reading\n",
    "import pandas as pd\n",
    "\n",
    "# for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# seaborn adds some extra visual appeal to our plots\n",
    "import seaborn as sns\n",
    "\n",
    "# set some universal plot settings here\n",
    "plt.rcParams[\"figure.dpi\"] = 200 # default plot dpi\n",
    "sns.set_style('darkgrid') # see: https://seaborn.pydata.org/tutorial/aesthetics.html\n",
    "sns.set_context(\"notebook\", font_scale=0.65) \n",
    "%config InlineBackend.figure_format = 'retina' # make high res plots for high res displays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's check out the data before we read it:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, tell Jupyter where to find the csv data:\n",
    "aws18_datafile = 'data/IMAU_aws18_high-res_meteo_daily.csv'\n",
    "\n",
    "# and let's explore quickly before reading with pandas\n",
    "!head $aws18_datafile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can see that the data are separated by commas and have a Date/Time column, so let's read the file and use that as an index column. \n",
    "\n",
    "Let's also set tell pandas to read the Date/Time column as actual dates, not just a dumb index using `parse_dates=['Date/Time']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws18_df = pd.read_csv(aws18_datafile, index_col=['Date/Time'], parse_dates=['Date/Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what does the top of this dataframe object look like?\n",
    "aws18_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What about the end?\n",
    "aws18_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can also use the .info() function to get some, uh, info about the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws18_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Easy! Let's generate some basic summary information for the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws18_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *What do you think about the range of temperatures at AWS18?*\n",
    "\n",
    "**\n",
    "\n",
    "#### But what about those \"...\" columns?\n",
    "\n",
    "For extra wide datasets, we need to tell pandas to show us all the data, if that's what we want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "aws18_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here on out, we'll get all columns!\n",
    "\n",
    "#### Let's make a quick plot of 2 meter temperature and surface temperature to see how these relate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws18_df['TTT [°C] (at 2m height)'].plot(ylabel='Temperature [°C]')\n",
    "aws18_df['Surf temp [°C] (modelled)'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *This shows us how the skin (surface) temperature is limited to 0°C. Why?*\n",
    "\n",
    "\n",
    "And a result, in summer there is typically a near-surface **temperature inversion**: temperature increases with height above the surface.\n",
    "    \n",
    "It's also interesting to see that air temperatures > 0°C are an imperfect indicator of surface melt. \n",
    "* Note the times that T2m > 0°C, yet the skin temperature is < 0 °C (i.e., not melting despite \"warm\" air).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## What if we wanted to quickly assess what the conditions are when melt is happening?\n",
    "\n",
    "We can select only the data when melt is occurring according to the SEB model, and show the descriptive statistics for these hours quite easily.\n",
    "\n",
    "#### To do this, we want to use the `pandas.DataFrame.loc` function:\n",
    "\n",
    "* Docs here: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.loc.html\n",
    "* Good examples here: https://www.earthdatascience.org/courses/use-data-open-source-python/use-time-series-data-in-python/date-time-types-in-pandas-python/subset-time-series-data-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws18_df.loc[aws18_df['Melt rate [mm w.e.] (surface melt, within dt)']>0].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *How many days of melt occurred out of the total number?*\n",
    "\n",
    "#### *Take a look at 2m temperature now. How does this look?*\n",
    "\n",
    "#### *What about the mean radiative and turbulent fluxes?*\n",
    "\n",
    "**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What if we were interested in subsetting by time instead? \n",
    "\n",
    "#### Indexing based on our Date/Time index field is easy using `pandas.DataFrame.loc`\n",
    "\n",
    "For example, what if we just wanted data for summer 2017/18 (December 2017, January 2018, February 2018)?    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws18_df.loc['2017-12':'2018-02']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's get the descriptive stats now for that interval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws18_df.loc['2017-12':'2018-02'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How about selecting all Decembers? \n",
    "\n",
    "Pandas understands time operators, and since we have a date/time index and told pandas to parse the dates when we read the csv file, we can query for index values based on dates/times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws18_df.loc[aws18_df.index.month==12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What if we wanted to select multiple months, like all DJFs?\n",
    "\n",
    "One way is to select data where the month index is equal to 12 or 1 or 2.\n",
    "\n",
    "In python, `|` is a 'bitwise operator' meaning OR:\n",
    "* https://www.w3schools.com/python/python_operators.asp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this creates a new dataframe containing a subset of aws18_df where the index month is in D,J, or F.\n",
    "aws18_djf_df = aws18_df[(aws18_df.index.month==12) | (aws18_df.index.month==1) | (aws18_df.index.month==2)]\n",
    "aws18_djf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what's it look like?\n",
    "aws18_djf_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How's summer compare to winter?\n",
    "\n",
    "Let's create a JJA subset and then difference the descriptive statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws18_jja_df = aws18_df[(aws18_df.index.month==6) | (aws18_df.index.month==7) | (aws18_df.index.month==8)]\n",
    "aws18_jja_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws18_jja_df.describe() - aws18_djf_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we didn't want all of those stats, but we just wanted to know what the mean difference was between those two seasons?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws18_jja_df.mean() - aws18_djf_df.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *So what have we learned from looking at AWS18 data so far?*\n",
    "\n",
    "It's colder in winter: on average 17.5°C colder. \n",
    "\n",
    "But the maximum (daily mean) temperature in JJA is quite high! +5.56°C (42°F) in the dark of the polar night! Only 0.74°C colder than the maximum mean daily temperature during summer. \n",
    "\n",
    "This is the fohn effect, which we'll explore in Part 3 of our introduction to Pandas. \n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a new fields in our DataFrame to track and compare summver vs non-summer melt events.\n",
    "\n",
    "How much melt occurs in winter? And what are the conditions like when winter melt occurs?\n",
    "Let's create a new boolean (True/False) field named non_summer_melt to track this.\n",
    "\n",
    "It should be True if: \n",
    "1. Melt > 0\n",
    "2. Month > 2 and < 12 (Month is between March and November)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws18_df['non_summer_melt'] = (aws18_df['Melt rate [mm w.e.] (surface melt, within dt)']>0) \\\n",
    "                        & (aws18_df.index.month>2) \\\n",
    "                        & (aws18_df.index.month<12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws18_df.loc[aws18_df['non_summer_melt']==True].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we just wanted to know the number of non-summer melt days? For that, we can call the `.value_counts` property:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws18_df['non_summer_melt'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's keep track summer melt by creating a summer_melt field in our DataFrame.\n",
    "\n",
    "This should be True if:\n",
    "1. Melt > 0\n",
    "2. Month < 3 or > 11 (Month is between December and February)\n",
    "\n",
    "Note that we'll want to place the two 'or' criteria within parenthases so that both are evaluated at the same time.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws18_df['summer_melt'] = (aws18_df['Melt rate [mm w.e.] (surface melt, within dt)']>0) \\\n",
    "                        & ((aws18_df.index.month<3) | (aws18_df.index.month>11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws18_df['summer_melt'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see that 263 days in DJF melt compared to 144 in any other month, or about ~65% of melt occurs in summer. That's surprisingly low!\n",
    "\n",
    "For a sanity check, we can double-check that we've accounted for all melt days (should be == 144 + 263) as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(aws18_df['Melt rate [mm w.e.] (surface melt, within dt)']>0).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK great, our trackers for non-summer melt get the same number of melt days as when we query the whole dataset for any days with melt.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's take a step back, and think about the radiative effects of clouds.\n",
    "\n",
    "1. Let's subset the data to a single year: 2016\n",
    "2. Smooth the data using a 10-day rolling mean to make them easier to interpret.\n",
    "3. Make a single plot with SWnet, LWnet, and Rnet on one axis, with Cloud coverage on a second axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset and then smooth\n",
    "aws18_df_subset = aws18_df.loc['2016-01-01':'2016-12-31']\n",
    "aws18_df_subset = aws18_df_subset.rolling(10, center=True).mean()\n",
    "\n",
    "# Create figure and plot space\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "# Plot data (here we're also assigning variables to our plots so that we can reference them later on)\n",
    "swnet = ax.plot(aws18_df_subset['Net SW [W/m**2]'], label=\"SWnet\", color=\"darkorange\")\n",
    "\n",
    "lwnet = ax.plot(aws18_df_subset['Net LW [W/m**2]'], label=\"LWnet\", color=\"indianred\")\n",
    "\n",
    "rnet = ax.plot(aws18_df_subset['NET [W/m**2]'], label=\"Rnet\", color=\"dimgrey\")\n",
    "\n",
    "# Add additional data to a second y axis\n",
    "ax2 = ax.twinx() # make second axis\n",
    "ax2.grid(False) # turn its grid lines off\n",
    "\n",
    "clouds = ax2.plot(aws18_df_subset['Cloud cov [%]'], label=\"Cloud cover\", color=\"steelblue\")\n",
    "\n",
    "# Set title and labels for axes\n",
    "ax.set(ylabel = 'Energy flux [W/m**2]', title='AWS18')\n",
    "ax2.set(ylabel = 'Cloud Cover [%]')\n",
    "\n",
    "# create a combined legend (needed because we have 2 y-axes)\n",
    "lines = swnet+lwnet+rnet+clouds # create list of all lines\n",
    "labs = [l.get_label() for l in lines] # loop through the list of lines and get their labels\n",
    "legend = ax.legend(lines, labs, loc='upper right', ncol=2) # plot the legend\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** \n",
    "\n",
    "# Practice sessions\n",
    "\n",
    "#### Question 1: Are the winter peaks in clouds associated with warm air advection?\n",
    "\n",
    "Assess this by plotting 10-day rollng means of T2m and cloud cover for this year.\n",
    "\n",
    "Recall:\n",
    "* That we can subset a dataset that is indexed based on a parsed date field using `.loc['':'']` as shown above.\n",
    "* Also, that in part 1 of this intro to Pandas, we called the `DataFrame.rolling` method and applied the `.mean()` function to calculate rolling means of data.\n",
    "* Lastly, that we can create a second y axis on which to plot data using `ax2 = ax.twinx()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2: What's different when it's extremely cloudy vs when it's mostly clear?\n",
    "1. Calculate the 5% and 95% percentile values for clouds. (hint: use the `DataFrame.quantile` function)\n",
    "2. Subset the data based on these values\n",
    "3. Calculate the difference in the descriptive statistics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3: Is there a seasonal effect on the effect of clouds on the surface meteorology?\n",
    "1. Create two subsets of data: DJF of all years and JJA of all years. Then do the same as above:\n",
    "    1. Calculate the 5% and 95% percentile values for clouds. (hint: use the `DataFrame.quantile` function)\n",
    "    2. Subset the data based on these values\n",
    "    3. Calculate the difference in the descriptive statistics in summer vs winter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geospatial-geog497",
   "language": "python",
   "name": "geospatial-geog497"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
